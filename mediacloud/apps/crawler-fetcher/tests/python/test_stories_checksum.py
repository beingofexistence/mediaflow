from mediawords.db import connect_to_db
from mediawords.util.text import random_string

# noinspection PyProtectedMember
from crawler_fetcher.stories_checksum import _stories_checksum, stories_checksum_matches_feed


def test_stories_checksum():
    """
    Test whether checksums generated by stories_checksum() are the same as generated by the previous Perl version.

    We have a gazillion of stories checksummed using Perl, so we need to ensure that Python generates same checksums for
    identical inputs.

    Perl code for checksumming:

        use strict;
        use warnings;
        use utf8;

        use Data::Dumper;
        use Digest::MD5 qw/md5_hex/;
        use Encode;

        sub stories_checksum($)
        {
            my ( $stories ) = @_;
            my $story_url_concat = join( '|', map { $_->{ url } } @{ $stories } );
            my $checksum = md5_hex( encode( 'utf8', $story_url_concat ) );
            return $checksum;
        }

        my $story_lists = [
            [
                # A single URL
                {'url' => 'http://test'},
            ],
            [
                # Two URLs
                {'url' => 'http://test'},
                {'url' => 'http://test2'}
            ],
            [
                # No URLs
            ],
            [
                # UTF-8 URL
                {'url' => 'http://www.yjc.ir/fa/news/5649486/جراحی-موفقیت-آمیز-جغد-زخمی-در-قم-تصاویر'},
            ],
        ];

        for my $stories ( @{ $story_lists } ) {
            print Dumper({
                'stories' => $stories,
                'checksum' => stories_checksum( $stories ),
            });
        }

    """

    assert _stories_checksum(stories=[{'url': 'http://test'}]) == '4dfb4ca3e76fafd4a7e65c2f3b137ad0', "A single URL."
    assert _stories_checksum(stories=[
        {'url': 'http://test'},
        {'url': 'http://test2'},
    ]) == '6d57ee7c312d8f7f339979ceb4362a82', "Two URLs."
    assert _stories_checksum(stories=[]) == 'd41d8cd98f00b204e9800998ecf8427e', "No URLs."
    assert _stories_checksum(stories=[
        {'url': 'http://www.yjc.ir/fa/news/5649486/جراحی-موفقیت-آمیز-جغد-زخمی-در-قم-تصاویر'},
    ]) == 'c5dae0c5ae1d78c85a262c3c56dbbfa6', "UTF-8 URL."


def test_stories_checksum_matches_feed():
    db = connect_to_db()

    rand = random_string(length=8)

    medium = db.create(table='media', insert_hash={
        'name': f"test feed checksum {rand}",
        'url': f"url://test/feed/checksum/{rand}",
    })
    feed = db.create(table='feeds', insert_hash={
        'name': 'feed',
        'url': medium['url'],
        'media_id': medium['media_id'],
    })
    feeds_id = feed['feeds_id']

    urls_a = [
        "http://www.bzf.ro/rezultate-liga-a-v-a-zona-fagaras-20.html",
        "http://www.mehrnews.com/detail/News/2027821",
        "http://www.chip.de/news/Parallels-Zwei-Android-Systeme-auf-einem-Handy_61383826.html",
        "http://www.inn.co.il/News/Flash.aspx/401095",
        (
            "http://www.moheet.com/2013/04/07/%d9%85%d8%ad%d8%b3%d9%88%d8%a8-%d8%a3%d8%ad%d8%af%d8%a7%d8%ab-%d8%a7%d9"
            "%84%d9%83%d8%a7%d8%aa%d8%af%d8%b1%d8.%a7%d8%a6%d9%8a%d8%a9-%d9%88%d8%a7%d8%ad%d8%af%d8%a9-%d9%85%d9%86-%d9"
            "%85%d9%88%d8%b1%d9%88/"
        ),
        "http://twitter.com/radiationn/statuses/320948496549154816",
        "http://news.chinatimes.com/realtime/110105/112013040700840.html",
        "http://www.northkoreannews.net/index.php/sid/213669147/scat/08aysdf7tga9s7f7",
        "http://twitter.com/NastyaaPatrick/statuses/320956956149948417",
        "http://life.chinatimes.com/life/11051801/112013040800054.html",
        "http://www.enet.gr/?i=news.el.article&id=355553",
        (
            "http://www.ibtimes.co.uk/articles/454410/20130407/portugal-government-sticks-to-bailout-goals-despite-"
            "court-ruling.htm"
        ),
        "http://www.egynews.net:80/wps/portal/news?params=223267",
        (
            "http://www.merkur-online.de:80/sport/fussball/hannover-trostlose-nullnummer-gegen-stuttgart-zr-"
            "2838522.html?cmp=defrss"
        ),
        "http://www.farsnews.com/newstext.php?nn=13920118001322",
    ]

    urls_b = [
        "http://www.guardian.co.uk/football/blog/2013/apr/07/sunderland-chelsea-tactics-match",
        (
            "http://www.nicematin.com/monde/egypte-un-mort-dans-des-violences-apres-les-funerailles-de-coptes-tues."
            "1206791.html"
        ),
        (
            "http://www.mercurynews.com/breaking-news/ci_22965002/immigration-talks-between-california-farm-groups-"
            "hit-impasse?source=rss_emailed"
        ),
        "http://www.belfasttelegraph.co.uk/sport/racing/cut-too-sharp-for-gladness-rivals-29179755.html",
        "http://www.vz.ru/news/2013/4/7/627732.html",
        "http://www.thehindu.com/sport/ipl2013/fleming-unhappy-with-csk-batsmen/article4591746.ece",
        (
            "http://www.dallasnews.com/entertainment/music/headlines/20130407-academy-of-country-music-awards-7-p.m.-"
            "burleson-s-kelly-clarkson-set-to-perform.ece"
        ),
        "http://feedproxy.google.com/~r/OTB/~3/TNKm_R0dEKo/",
        (
            "http://rss.feedsportal.com/c/266/f/3492/s/2a6f8876/l/0L0Sindependent0O0Cnews0Cworld0Cmiddle0Eeast0Cisraels"
            "0Enew0Estrategic0Eaffairs0Eminister0Ewest0Emust0Ethreaten0Eiran0Eover0Enuclear0Eplans0E85635150Bhtml/"
            "story01.htm"
        ),
        "http://news.chinatimes.com/focus/11050105/112013040800090.html",
        "http://blogi.newsweek.pl/Tekst/naluzie/669783,marzenie-przyziemne.html#comment-168169",
        "http://jamaica-gleaner.com/gleaner/20130407/ent/ent6.html",
        "http://www.wboc.com/story/21901967/timeline-of-the-whereabouts-of-suspected-strangler",
        "http://www.cadenaser.com/internacional/articulo/feminismo-islamico-femen/csrcsrpor/20130407csrcsrint_6/Tes",
        "http://thehimalayantimes.com/rssReference.php?id=MzcyMDQw",
        (
            "http://au.ibtimes.com/articles/454410/20130408/portugal-government-sticks-to-bailout-goals-despite-court-"
            "ruling.htm"
        ),
        "http://www.ziar.com/articol-din-ziar?id_syndic_article=5566035",
        "http://www.bellinghamherald.com/2013/04/07/2955579/hardwood-to-trading-floor-stocks.html#storylink=rss",
    ]

    stories_a = [{'url': url} for url in urls_a]
    stories_b = [{'url': url} for url in urls_b]

    # First check should fail since feed checksum should be empty
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_a) is False, "Empty checksum."

    # Next check with same stories should be a match
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_a) is True, "Match 1."

    # And another match
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_a) is True, "Match 2."

    # And now try with different set of stories
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_b) is False, "Fail 1."

    # And now with the same B stories
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_b) is True, "Match 3."

    # And now add one story
    stories_b.append({'url': 'http://foo.bar.com'})
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_b) is False, "Fail 2."
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_b) is True, "Match 4."

    # And now with no stories
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=[]) is False, "Fail 3."

    # And now with B again
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_a) is False, "Fail 4."
    assert stories_checksum_matches_feed(db=db, feeds_id=feeds_id, stories=stories_a) is True, "Match 5."
